{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07296a1",
   "metadata": {},
   "source": [
    "# Nurse Scheduling Problem\n",
    "\n",
    "This notebook demonstrates how to use **qubo** and slack variables to model the nurse scheduling problem(NSP). The model will be analyzed and transformed by using **pyqubo** to matrix elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cfee5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import calendar\n",
    "import re\n",
    "import json\n",
    "\n",
    "from pyqubo import Binary, Array, Constraint, Model, And, Or, Not, Num\n",
    "\n",
    "from lib.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f049059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_configuration_to_solution(config, variables):\n",
    "    data = {}\n",
    "    for var in variables:\n",
    "        if config[str(variables.index(var))]:\n",
    "            data[var] = 1\n",
    "        else:\n",
    "            data[var] = 0\n",
    "    return data\n",
    "\n",
    "def generate_shift_from_solution(per_grave, days, solution_dict):\n",
    "    table = np.zeros((per_grave, days))\n",
    "    for key, value in solution_dict.items():\n",
    "        if \"Graveyard\" in key and \"*\" not in key:\n",
    "            indexes = re.findall(r'\\[(\\d+)\\]', key)\n",
    "            indexes = [int(index) for index in indexes]\n",
    "            table[indexes[0]][indexes[1]] = value\n",
    "#     table = table.reshape(per_gravdays).astype(int)\n",
    "    return table\n",
    "\n",
    "def get_weekend_date(year, month):\n",
    "    \"\"\"\n",
    "    Get the weekend date of a month\n",
    "    :param year: int\n",
    "    :param month: int\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    calendar_matrix = calendar.monthcalendar(year, month)\n",
    "    weekend_date = []\n",
    "    weekends = []\n",
    "    # complexity: number of weekend_date\n",
    "    for week in calendar_matrix:  # 4~5\n",
    "        weekend_date = week[-2:]\n",
    "        for date in weekend_date:  # 2\n",
    "            if date > 0:\n",
    "                weekends.append(date - 1)\n",
    "\n",
    "    return weekends\n",
    "\n",
    "def convert_hamiltonian_to_binary_polynomial_term(hamiltonian, variables):\n",
    "    model = hamiltonian.compile()\n",
    "    qubo, offset = model.to_qubo()\n",
    "    # variables = model.variables\n",
    "    binary_polynomial_terms = []\n",
    "\n",
    "    for key, value in qubo.items():\n",
    "        # print(key, value)\n",
    "\n",
    "        binary_polynomial_terms.append({\n",
    "            'c' : value,\n",
    "            'p' : [\n",
    "                variables.index(key[0]),\n",
    "                variables.index(key[1])\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    binary_polynomial_terms.append({\n",
    "        'c' : offset,\n",
    "        'p' : []\n",
    "    }) \n",
    "\n",
    "    return binary_polynomial_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32f234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(solution, solution_index, model, number_of_workers, days):\n",
    "\n",
    "    with open(\"solution{}.json\".format(job_id), 'w') as file:\n",
    "        json.dump(solution, file, indent=4)\n",
    "\n",
    "    solution_dict = []\n",
    "    for i in range(len(solution['qubo_solution']['solutions'])):\n",
    "        solution_dict.append(\n",
    "            convert_configuration_to_solution(solution['qubo_solution']['solutions'][i]['configuration'], model.variables))\n",
    "\n",
    "    decoded_sample = model.decode_sample(solution_dict[solution_index], vartype='BINARY')\n",
    "    print(json.dumps(solution['qubo_solution']['progress'], indent=4))\n",
    "    print(json.dumps(decoded_sample.constraints(), indent=4))\n",
    "\n",
    "    table = generate_shift_from_solution(number_of_workers, days, decoded_sample.sample)\n",
    "    table = pd.DataFrame(table, dtype=int, columns=range(1, days+1))\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a225c3",
   "metadata": {},
   "source": [
    "## Constraint Functions\n",
    "\n",
    "Here defines the constraint function class. The class should have the ability to calculate its hamiltonian and the evaluate of the constraint after having the result from the digital annealing solver.\n",
    "\n",
    "Origianlly, the **pyqubo** and the **bqm** have function to know if the result satifies with the constraints and gives the programmer True and False. However, only True and False values are not sufficient to represent the quality of result. The result is not always perfect, and would have some constraints that are challenging to be satisfied, but the digital annealing solver has tried its best to lower down the energy. In view of this, the correctness ratio is necessary.\n",
    "\n",
    "the abstract base class of constraint function should be in the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3be8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstraintFunction(object):\n",
    "    \n",
    "    def __init__(self, X:Array):\n",
    "        self._X = X\n",
    "        \n",
    "    def hamiltonian(self) -> Model:\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, table):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce497804",
   "metadata": {},
   "source": [
    "In the above snippet of code, the `hamiltonian` method should return the `Model` type of variable that represent the constraint defined in this class. For the `evaluate` method, it returns float numbers which are the quality  and std of the shift table for this constraint. The higher the value, the higher the quality and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f02cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpectedWorkingDays(ConstraintFunction):\n",
    "    \n",
    "    def __init__(self, X:Array, expected_working_days):\n",
    "        super().__init__(X)\n",
    "        \n",
    "        self._expected_working_days = expected_working_days\n",
    "        \n",
    "    def hamiltonian(self):\n",
    "        workers, days = self._X.shape\n",
    "        H = Num(0)\n",
    "        for r in range(workers):\n",
    "            H += (sum([self._X[r][day] for day in range(1, days)], start=self._X[r][0]) - self._expected_working_days)**2\n",
    "        return H\n",
    "    \n",
    "    def evaluate(self, table):\n",
    "        \n",
    "        content = table.values\n",
    "        rows, cols = content.shape\n",
    "        \n",
    "        failed_rates = []\n",
    "        for r in range(rows):\n",
    "            diff = self._expected_working_days - sum(content[r])\n",
    "            if (diff != 0):\n",
    "                print(\"Worker %d failed => %d\" % (r, diff))\n",
    "            failed_rates.append(abs(diff) / self._expected_working_days)\n",
    "         \n",
    "        \n",
    "        return np.average(failed_rates), np.std(failed_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada17bc1",
   "metadata": {},
   "source": [
    "#### Expected Number of Workers in Each Shift\n",
    "\n",
    "**Terminology**\n",
    "*Shift*: A day in the shift table\n",
    "\n",
    "The following constraint defines the expected number of workers in each shift. This constraint is common and used to balance the workforce and the workload on each day. The constraint is modeled by summing up the variables on each shift and minus the expected number of workers and, finally, double themselves and make them quadratic.\n",
    "\n",
    "As for the `evaluate` method, it scans the shift day for each day and check if the shifts satisfy the constraint or not. The method would return a float number that represent the rate of correction. In addition, the method prints out which date is failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3add4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpectedNumberOfWorkersInEachShift(ConstraintFunction):\n",
    "    \n",
    "    def __init__(self, X:Array, expected_workers):\n",
    "        \n",
    "        super().__init__(X)\n",
    "        self._expected_workers = expected_workers\n",
    "        \n",
    "    def hamiltonian(self):\n",
    "        shifts = []\n",
    "        workers, days = X.shape\n",
    "        H = 0\n",
    "        for i in range(days):\n",
    "            shift = 0\n",
    "            for j in range(workers):\n",
    "                shift += X[j][i]\n",
    "            H += (shift - self._expected_workers) ** 2\n",
    "            \n",
    "        return H\n",
    "    \n",
    "    def evaluate(self, table):\n",
    "        print(\"Evaluate on expected number of workers on each shift\")\n",
    "        failed = 0\n",
    "        for i in table.columns:\n",
    "            _sum = table[i].sum()\n",
    "            if _sum < self._expected_workers:\n",
    "                failed += 1\n",
    "                print(\"\\tdate[%d] Failed\" % (i))\n",
    "        correct_rate = failed / len(table.columns)\n",
    "        \n",
    "        return 1 - correct_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e896b0",
   "metadata": {},
   "source": [
    "#### Max Consecutive Shifts\n",
    "\n",
    "The constraint setup a limit on maximum number of consecutive shifts. The following constraint uses the slack variables to model the constraint. However, the use of slack variables increase the scale of the problem, i.e. the number of variables, and make the problem intractable. In view of this, the Fujitsu Limited **inequalities** terms to decrease the scale of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d62956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxConsecutiveShifts(ConstraintFunction):\n",
    "    \n",
    "    def __init__(self, X:Array, max_consecutive_day):\n",
    "        super().__init__(X)\n",
    "        \n",
    "        self._max_consecutive_day = max_consecutive_day\n",
    "        \n",
    "    \n",
    "    def hamiltonian(self):\n",
    "        shift_cycles = []\n",
    "        row, col = self._X.shape\n",
    "        for i in range(row):\n",
    "            shift_cycle = []\n",
    "            for j in range(col - self._max_consecutive_day):\n",
    "                shift_cycle.append( sum([self._X[i][p] for p in range(j, j + self._max_consecutive_day)], start=self._X[i][j+self._max_consecutive_day]) )\n",
    "            shift_cycles.append(shift_cycle)\n",
    "        \n",
    "        cycle = col - self._max_consecutive_day\n",
    "        \n",
    "        slack_initial = Array.create(\"slack1\", shape=row * cycle * self._max_consecutive_day, vartype=\"BINARY\")\n",
    "        slack = np.zeros(row * cycle * self._max_consecutive_day).reshape(row, cycle * self._max_consecutive_day)\n",
    "        slack = slack.tolist()\n",
    "        print(slack_initial.shape)\n",
    "\n",
    "        for i in range(row):\n",
    "            for j in range(cycle * self._max_consecutive_day):\n",
    "                slack[i][j] = slack_initial[cycle * self._max_consecutive_day * i + j]\n",
    "        \n",
    "        H = 0\n",
    "        for i in range(row):\n",
    "            for j in range(cycle):\n",
    "                # To adapt the condition k is not equal to 4, a for-loop needed\n",
    "                H += (shift_cycles[i][j] - sum(slack[i][l]\n",
    "                                                for l in range(self._max_consecutive_day * j, self._max_consecutive_day *(j+1))) )**2\n",
    "                \n",
    "        return H\n",
    "    \n",
    "    def evaluate(self, table):\n",
    "        print(\"Evaluate on the limit of max consecutive shifts:\")\n",
    "        content = table.values\n",
    "        row, col = content.shape\n",
    "        failed = 0\n",
    "        for r in range(row):\n",
    "            for c in range(col - self._max_consecutive_day - 1):\n",
    "                if(sum(content[r][c:c+self._max_consecutive_day+1]) > self._max_consecutive_day):\n",
    "                    failed += 1\n",
    "                    print(\"\\tworker[%d], date[%d] Failed\" % (r+1, c+1))\n",
    "\n",
    "        correctness_rate = 1 - (failed / (row*(col - self._max_consecutive_day)))\n",
    "        \n",
    "        return correctness_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca895e",
   "metadata": {},
   "source": [
    "#### Max Consecutive Shifts Inequalities\n",
    "\n",
    "This constraint inherit the above constraint, sharing the same `evaluate` method and override the hamiltonian method. Please refer to the [link](https://portal.aispf.global.fujitsu.com/apidoc/da/jp/api-ref/da-qubo-v3-en.html) to make yourself familiar with the way to model the inequalities on DAU service. This can decrease the number of the variables and make the annealing progress focus on the critical variables instead of stack variables and intermediate terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97039b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxConsecutiveShiftsInequalities(MaxConsecutiveShifts):\n",
    "    \n",
    "    def __init__(self, X, max_consecutive_days):\n",
    "        super().__init__(X, max_consecutive_days)\n",
    "    \n",
    "    def hamiltonian(self):\n",
    "        \n",
    "        return Num(0)\n",
    "    \n",
    "    \n",
    "    def inequalities(self, variables: list):\n",
    "        shift_cycles = []\n",
    "        row, col = self._X.shape\n",
    "        for i in range(row):\n",
    "            shift_cycle = []\n",
    "            for j in range(col - self._max_consecutive_day):\n",
    "                shift_cycle.append(sum([self._X[i][p] for p in range(j, j+self._max_consecutive_day+1)], start=Num(-self._max_consecutive_day)))\n",
    "            shift_cycles.append(shift_cycle) \n",
    "        terms = []\n",
    "        for shift_cycle in shift_cycles:\n",
    "            for cycle in shift_cycle:\n",
    "                term = convert_hamiltonian_to_binary_polynomial_term(cycle, variables)\n",
    "                terms.append(term)\n",
    "            \n",
    "        return terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993886f",
   "metadata": {},
   "source": [
    "#### Two Consecutive Shift\n",
    "\n",
    "This constraint is placed to make each worker has at least two consecutive shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f108c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoConsecutiveShift(ConstraintFunction):\n",
    "    \n",
    "    def __init__(self, X:Array):\n",
    "        super().__init__(X)\n",
    "        \n",
    "    def hamiltonian(self):\n",
    "        row, col = self._X.shape\n",
    "        Hc = 0\n",
    "        for i in range(row):\n",
    "            for j in range(col - 2):\n",
    "                Hc = Hc + And(self._X[i][j + 1], 1 - Or(self._X[i][j], self._X[i][j + 2]))\n",
    "            Hc = Hc + (And(self._X[i][0], Not(self._X[i][1]))) + (And(self._X[i][col - 1], Not(self._X[i][col - 2])))\n",
    "        return Hc\n",
    "        \n",
    "    def evaluate(self, table):\n",
    "        \n",
    "        content = table.values\n",
    "        row, col = content.shape\n",
    "        failed = 0\n",
    "        for r in range(row):\n",
    "            for c in range(1, col-1):\n",
    "                if content[r][c] == 1 and content[r][c-1] == 0 and content[r][c+1] == 0:\n",
    "                    failed += 1\n",
    "            if (content[r][0] == 1 and content[r][1] == 0) or (content[r][col - 1] == 1 and content[r][col - 2] == 0):\n",
    "                failed += 1\n",
    "                    \n",
    "        possible_outcomes = row * col\n",
    "        \n",
    "        return 1 - (failed / possible_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e8bf5",
   "metadata": {},
   "source": [
    "### Day-off constraint\n",
    "\n",
    "There are two predominant constraints on day-off. One focus on the days off in a range of days, and the other is on the relationship between each day-off\n",
    "\n",
    "#### WeekdayLeaveConstraint\n",
    "\n",
    "The first is `WeekdayLeaveConstraint` which is imposed to enable each nurse to have at least 2 days off in 7 days. There are two means to model this constraint, one could use the slack variables, and another could use the inequalities feature provided by the V3 api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f00f15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeekdayLeaveConstraint(ConstraintFunction):\n",
    "    \n",
    "    def __init__(self, X:Array, weekend):\n",
    "        \n",
    "        super().__init__(X)\n",
    "        self._weekend = weekend\n",
    "        \n",
    "    def hamiltonian(self):\n",
    "        row, col = self._X.shape\n",
    "        \n",
    "        days = col\n",
    "        week_slack = Array.create(\"slack2\", shape=(row, col), vartype=\"BINARY\")\n",
    "        print(self._X.shape)\n",
    "        H = 0\n",
    "        for j in range(row):\n",
    "            for i in self._weekend[::2]:\n",
    "                if i + 7 < days:\n",
    "                    H = H + (sum(self._X[j][l] for l in range(i, i + 7)) -\n",
    "                               sum(week_slack[j][l] for l in range(i, i + 5)))**2\n",
    "                elif i + 5 < days and i + 7 > days:\n",
    "                    H = H + (sum(self._X[j][l] for l in range(i, days)) -\n",
    "                               sum(week_slack[j][l] for l in range(i, i + 5)))**2\n",
    "        return H\n",
    "    \n",
    "    def evaluate(self, table):\n",
    "        content = table.values\n",
    "        rows, cols = content.shape\n",
    "        failed = 0\n",
    "        \n",
    "        days = cols\n",
    "        for r in range(rows):\n",
    "            for i in self._weekend[::2]:\n",
    "                if i + 7 < days:\n",
    "                    if sum(content[r][i:i+7]) > 5:\n",
    "                        failed += 1\n",
    "                if i + 5 < days and i + 7 > days:\n",
    "                    if sum(content[r][i:]) > 5:\n",
    "                        failed += 1\n",
    "        return 1 - (failed / (len(self._weekend[::2])*rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1a742",
   "metadata": {},
   "source": [
    "#### Weekday Leave Constraint Inequalities\n",
    "\n",
    "The following constraint inherits the constraint defined above and share the same correctness method. The predominant difference lies on the way to model the problem. The parent class uses slack varaibles, and the child class uses inequalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f42fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeekdayLeaveConstraintInequalities(WeekdayLeaveConstraint):\n",
    "    \n",
    "    def __init__(self, X:Array, weekend):\n",
    "        super().__init__(X, weekend)\n",
    "        \n",
    "    def inequalities(self, variables):\n",
    "        row, col = self._X.shape\n",
    "        hamiltonians = []\n",
    "        for j in range(row):\n",
    "            for i in self._weekend[::2]:\n",
    "                if i + 7 < days:\n",
    "                    hamiltonians.append(sum([self._X[j][l] for l in range(i, i + 7)], start=-Num(5)))\n",
    "                elif i + 5 < days and i + 7 > days:\n",
    "                    hamiltonians.append(sum([self._X[j][l] for l in range(i, days)], start=-Num(5)))\n",
    "        \n",
    "        terms = []\n",
    "        \n",
    "        for i in range(len(hamiltonians)):\n",
    "            terms.append(convert_hamiltonian_to_binary_polynomial_term(hamiltonians[i], variables))\n",
    "            \n",
    "        return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e63ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Consecutive2DaysLeaves(ConstraintFunction):\n",
    "    \n",
    "    def __init__(self, X):\n",
    "        super().__init__(X)\n",
    "        \n",
    "    def hamiltonian(self):\n",
    "        row, col = self._X.shape\n",
    "        H = Num(0)\n",
    "        for i in range(row):\n",
    "            for j in range(col - 1):\n",
    "                H += (1 - self._X[i][j] * self._X[i][j + 1])\n",
    "                \n",
    "        return H\n",
    "    \n",
    "    \n",
    "    def evaluate(self, table):\n",
    "        content = table.values\n",
    "        rows, cols = content.shape\n",
    "        \n",
    "        all_leaves = 0\n",
    "        all_consecutive_2days_leave = 0\n",
    "        for r in range(rows):\n",
    "            row = ''.join([str(shift) for shift in content[r]])\n",
    "            all_leaves += len(re.findall(r'0+', row))\n",
    "            \n",
    "            consecutive_days_off = re.findall(r'(00)+0*', row)\n",
    "            single_day_off = re.findall(r'0+', row)\n",
    "#             print(\"\\trow : \", row, end='=>')\n",
    "#             print(\"\\t cons days off\", consecutive_days_off, end='====>')\n",
    "#             print(\"\\t single day off\", single_day_off)\n",
    "            \n",
    "            all_consecutive_2days_leave += len(consecutive_days_off)\n",
    "            \n",
    "        return (all_consecutive_2days_leave / all_leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f053eb",
   "metadata": {},
   "source": [
    "## Preliminary setup\n",
    "\n",
    "In this section, each block will setup the variables and constraints\n",
    "\n",
    "### Variables\n",
    "\n",
    "The shift could be generated for a specific month. The initial number of variables are the number of days times number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d34f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nurses = 10\n",
    "year = 2022\n",
    "month = 9\n",
    "first_date, days = calendar.monthrange(year, month)\n",
    "X = Array.create(\"Graveyard\", shape=(number_of_nurses, days), vartype=\"BINARY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebac3e41",
   "metadata": {},
   "source": [
    "### Constraints and Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6391e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmda = 0.1\n",
    "exp_workers_constraint = ExpectedNumberOfWorkersInEachShift(X, 7)\n",
    "Ha = Constraint(exp_workers_constraint.hamiltonian(), \"expected number of workers on each shift\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66ff4c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250,)\n"
     ]
    }
   ],
   "source": [
    "lmdb = 0.5\n",
    "max_consecutive_working_days = 5\n",
    "max_consecutive_shifts_constraint = MaxConsecutiveShifts(X, max_consecutive_working_days)\n",
    "Hb = Constraint(max_consecutive_shifts_constraint.hamiltonian(), \"The Limit of max consecutive working days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93d65844",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdc = 0.5\n",
    "two_consecutive_shift = TwoConsecutiveShift(X)\n",
    "Hc = Constraint(two_consecutive_shift.hamiltonian(), \"Two consecutive working days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c370f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 30)\n"
     ]
    }
   ],
   "source": [
    "# a weekday leave\n",
    "weekends = get_weekend_date(year, month)\n",
    "lmdd = 0.5\n",
    "weekday_leave_constraint_slack_var = WeekdayLeaveConstraint(X, weekends)\n",
    "Hd = Constraint(weekday_leave_constraint_slack_var.hamiltonian(), \"weekday leave constraint by using slack variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1fe7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmde = 1\n",
    "consecutive_2_day_off = Consecutive2DaysLeaves(X)\n",
    "He = Constraint(consecutive_2_day_off.hamiltonian(), \"Consecutive 2 days off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41210747",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdf = 1\n",
    "expected_number_of_working_days = days - len(weekends)\n",
    "exp_num_working_dys_constraint = ExpectedWorkingDays(X, expected_number_of_working_days)\n",
    "Hf = Constraint(exp_num_working_dys_constraint.hamiltonian(), \"Expected number of working days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f3baf",
   "metadata": {},
   "source": [
    "### Model with slack variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2da9310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables :  1840\n"
     ]
    }
   ],
   "source": [
    "H_slack = lmda*Ha + lmdb*Hb + lmdc*Hc + lmdd*Hd + lmde*He + lmdf*Hf\n",
    "model_slack_var = H_slack.compile()\n",
    "qubo, offset = model_slack_var.to_qubo()\n",
    "VARIABLES = model_slack_var.variables\n",
    "matrix_terms_slack = get_matrix_term(qubo, VARIABLES)\n",
    "print(\"Number of variables : \", len(VARIABLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f96c06de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'success'}\n",
      "0f03efef-ac2a-4eb4-a69c-03997d20cbb9-231774816876673\n"
     ]
    }
   ],
   "source": [
    "problem_body = {}\n",
    "DA_Solver = {}\n",
    "DA_Solver[\"time_limit_sec\"]= 180\n",
    "DA_Solver[\"penalty_coef\"]=10000\n",
    "DA_Solver[\"num_run\"] = 16\n",
    "DA_Solver[\"num_group\"] = 16\n",
    "DA_Solver['gs_level'] = 90\n",
    "DA_Solver['gs_cutoff'] = 900000\n",
    "problem_body[\"fujitsuDA3\"]=DA_Solver\n",
    "problem_body[\"binary_polynomial\"] = {'terms' : matrix_terms_slack}\n",
    "job_id = post_solve(problem_body).json()['job_id']\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e36edce",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d551f65b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "solutions = get_solution(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba5d835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"energy\": -5260.200000000117,\n",
      "        \"time\": 60.925\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5260.800000000117,\n",
      "        \"time\": 120.045\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5261.300000000112,\n",
      "        \"time\": 149.647\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5261.600000000114,\n",
      "        \"time\": 149.649\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5261.700000000119,\n",
      "        \"time\": 180.017\n",
      "    }\n",
      "]\n",
      "{\n",
      "    \"Expected number of working days\": [\n",
      "        true,\n",
      "        0.0\n",
      "    ],\n",
      "    \"Consecutive 2 days off\": [\n",
      "        false,\n",
      "        111.0\n",
      "    ],\n",
      "    \"The Limit of max consecutive working days\": [\n",
      "        false,\n",
      "        35.0\n",
      "    ],\n",
      "    \"Two consecutive working days\": [\n",
      "        true,\n",
      "        0.0\n",
      "    ],\n",
      "    \"weekday leave constraint by using slack variables\": [\n",
      "        false,\n",
      "        10.0\n",
      "    ],\n",
      "    \"expected number of workers on each shift\": [\n",
      "        false,\n",
      "        38.0\n",
      "    ]\n",
      "}\n",
      "Expected Number of working days, average failed rates : (0.000, 0.000)\n",
      "######Evaluate on the limit of max consecutive shifts:\n",
      "\tworker[1], date[6] Failed\n",
      "\tworker[1], date[14] Failed\n",
      "\tworker[2], date[4] Failed\n",
      "\tworker[2], date[12] Failed\n",
      "\tworker[2], date[20] Failed\n",
      "\tworker[3], date[10] Failed\n",
      "\tworker[3], date[18] Failed\n",
      "\tworker[3], date[19] Failed\n",
      "\tworker[4], date[8] Failed\n",
      "\tworker[4], date[16] Failed\n",
      "\tworker[5], date[4] Failed\n",
      "\tworker[5], date[18] Failed\n",
      "\tworker[5], date[19] Failed\n",
      "\tworker[5], date[20] Failed\n",
      "\tworker[6], date[2] Failed\n",
      "\tworker[6], date[10] Failed\n",
      "\tworker[7], date[6] Failed\n",
      "\tworker[7], date[14] Failed\n",
      "\tworker[8], date[6] Failed\n",
      "\tworker[8], date[7] Failed\n",
      "\tworker[8], date[8] Failed\n",
      "\tworker[8], date[9] Failed\n",
      "\tworker[8], date[10] Failed\n",
      "\tworker[8], date[20] Failed\n",
      "\tworker[8], date[21] Failed\n",
      "\tworker[8], date[22] Failed\n",
      "\tworker[8], date[23] Failed\n",
      "\tworker[9], date[5] Failed\n",
      "\tworker[9], date[6] Failed\n",
      "\tworker[9], date[7] Failed\n",
      "\tworker[9], date[8] Failed\n",
      "\tworker[9], date[9] Failed\n",
      "\tworker[9], date[10] Failed\n",
      "\tworker[10], date[10] Failed\n",
      "\tworker[10], date[18] Failed\n",
      "max consecutive shift :  0.86\n",
      "######\n",
      "consecutive 2 days-off:  0.15000000000000002\n",
      "######\n",
      "weekday leaves:  0.75\n",
      "######\n",
      "Evaluate on expected number of workers on each shift\n",
      "\tdate[1] Failed\n",
      "\tdate[2] Failed\n",
      "\tdate[4] Failed\n",
      "\tdate[16] Failed\n",
      "\tdate[17] Failed\n",
      "\tdate[30] Failed\n",
      "expected # of workers 0.8\n",
      "######\n",
      "at least 2 consecutive shift:  1.0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "table = decode(solutions, 0, model_slack_var, number_of_nurses, days)\n",
    "print(\"Expected Number of working days, average failed rates : (%.3f, %.3f)\" % exp_num_working_dys_constraint.evaluate(table), end=\"\\n######\")\n",
    "print(\"max consecutive shift : \", max_consecutive_shifts_constraint.evaluate(table), end=\"\\n######\\n\")\n",
    "print(\"consecutive 2 days-off: \", consecutive_2_day_off.evaluate(table), end=\"\\n######\\n\")\n",
    "print(\"weekday leaves: \", weekday_leave_constraint_slack_var.evaluate(table), end=\"\\n######\\n\")\n",
    "print(\"expected # of workers\", exp_workers_constraint.evaluate(table), end=\"\\n######\\n\")\n",
    "print(\"at least 2 consecutive shift: \", two_consecutive_shift.evaluate(table), end=\"\\n######\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c35865",
   "metadata": {},
   "source": [
    "### Replace slack variables with inequalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af069178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables :  440\n"
     ]
    }
   ],
   "source": [
    "H = lmda*Ha + lmdc*Hc + lmde*He + lmdf*Hf\n",
    "model = H.compile()\n",
    "qubo, offset = model.to_qubo()\n",
    "VARIABLES = model.variables\n",
    "matrix_terms = get_matrix_term(qubo, VARIABLES)\n",
    "print(\"Number of variables : \", len(VARIABLES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3025203",
   "metadata": {},
   "source": [
    "#### Add inequalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee77318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_consecutive_shift_inequalities = MaxConsecutiveShiftsInequalities(X, max_consecutive_working_days)\n",
    "max_consecutive_ineq_terms = max_consecutive_shift_inequalities.inequalities(VARIABLES)\n",
    "\n",
    "weekday_leaves_ineqs = WeekdayLeaveConstraintInequalities(X, weekends)\n",
    "weekday_leaves_ineq_terms = weekday_leaves_ineqs.inequalities(VARIABLES)\n",
    "\n",
    "inequalities = []\n",
    "for term in max_consecutive_ineq_terms:\n",
    "    inequalities.append({\n",
    "        \"terms\" : term\n",
    "    })\n",
    "    \n",
    "for term in weekday_leaves_ineq_terms:\n",
    "    inequalities.append({\n",
    "        \"terms\" : term\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4693e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_body = {}\n",
    "DA_Solver = {}\n",
    "DA_Solver[\"time_limit_sec\"]= 180\n",
    "DA_Solver[\"penalty_coef\"]=10000\n",
    "DA_Solver[\"num_run\"] = 16\n",
    "DA_Solver[\"num_group\"] = 16\n",
    "DA_Solver['gs_level'] = 90\n",
    "DA_Solver['gs_cutoff'] = 900000\n",
    "problem_body[\"fujitsuDA3\"]=DA_Solver\n",
    "problem_body[\"binary_polynomial\"] = { 'terms' : matrix_terms }\n",
    "problem_body[\"inequalities\"] = inequalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de378e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'success'}\n",
      "0f03efef-ac2a-4eb4-a69c-03997d20cbb9-231770835039423\n"
     ]
    }
   ],
   "source": [
    "job_id = post_solve(problem_body).json()['job_id']\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa6853",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4383ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = get_solution(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5f7ca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"energy\": -5149.400000000093,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 15.087\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5149.400000000099,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 15.088\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5149.600000000102,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 15.088\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5149.800000000097,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 22.575\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5150.000000000094,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 22.575\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5150.00000000009,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 22.576\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5150.20000000009,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 30.073\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5150.600000000095,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 30.073\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5150.800000000098,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 30.073\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5151.200000000093,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 30.073\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5151.300000000082,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 30.074\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5152.000000000093,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 37.547\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5152.600000000092,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 37.547\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5153.000000000093,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 45.033\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5153.200000000087,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 45.034\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5153.40000000008,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 45.034\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5153.800000000091,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 60.031\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5154.000000000078,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 67.566\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5154.000000000092,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 67.566\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5154.200000000079,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 75.068\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5154.20000000009,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 135.161\n",
      "    },\n",
      "    {\n",
      "        \"energy\": -5154.20000000009,\n",
      "        \"penalty_energy\": 0,\n",
      "        \"time\": 135.161\n",
      "    }\n",
      "]\n",
      "{\n",
      "    \"Expected number of working days\": [\n",
      "        true,\n",
      "        0.0\n",
      "    ],\n",
      "    \"Two consecutive working days\": [\n",
      "        true,\n",
      "        0.0\n",
      "    ],\n",
      "    \"Consecutive 2 days off\": [\n",
      "        false,\n",
      "        121.0\n",
      "    ],\n",
      "    \"expected number of workers on each shift\": [\n",
      "        false,\n",
      "        18.0\n",
      "    ]\n",
      "}\n",
      "Expected Number of working days, average failed rates : (0.000, 0.000)\n",
      "######Evaluate on the limit of max consecutive shifts:\n",
      "max consecutive shift :  1.0\n",
      "######\n",
      "consecutive 2 days-off:  0.6304347826086957\n",
      "######\n",
      "weekday leaves:  1.0\n",
      "######\n",
      "Evaluate on expected number of workers on each shift\n",
      "\tdate[7] Failed\n",
      "expected # of workers 0.9666666666666667\n",
      "######\n",
      "at least 2 consecutive shift:  1.0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "table = decode(solutions, 0, model, number_of_nurses, days)\n",
    "print(\"Expected Number of working days, average failed rates : (%.3f, %.3f)\" % exp_num_working_dys_constraint.evaluate(table), end=\"\\n######\")\n",
    "print(\"max consecutive shift : \", max_consecutive_shifts_constraint.evaluate(table), end=\"\\n######\\n\")\n",
    "print(\"consecutive 2 days-off: \", consecutive_2_day_off.evaluate(table), end=\"\\n######\\n\")\n",
    "print(\"weekday leaves: \", weekday_leave_constraint_slack_var.evaluate(table), end=\"\\n######\\n\")\n",
    "print(\"expected # of workers\", exp_workers_constraint.evaluate(table), end=\"\\n######\\n\")\n",
    "print(\"at least 2 consecutive shift: \", two_consecutive_shift.evaluate(table), end=\"\\n######\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
